---
category: blog
title: Why is functional programming awesome. A primer.
layout: blog
---

I really am not the best person to be the author such an article - I am not that into programming anymore, and I never was a real expert in it. However I am doing it, because I have been waiting for someone else to write it for years and kept noticing the following phenomena:

1. People who understand functional programming, cannot make themselves understood by the general (programming) public.
2. People who are able to make themselves understood by the public, don't understand enough for them to be worth listening. 

Roughly the same thing has been called  "the curse of the monad" by some people: "Once you understand it, you lose the ability to explain it".

It is clear now that monads are not something you get in an afternoon, but I think you can get some idea of what FP (functional programming) is in an afternoon. Or, you know, an year or so. But in order to spend that thime you need some motivation. You probably need someone to tell you why exactly do you need to know about FP. Why is it awesome, so to say. And so my article begins. Before starting, keep in mind that you need a clear mind to understand it. So for a second forget everything that you know about programming paradigms. Forget the Object Oriented religious bullshit, that you learned at school, or by reading different versions of the same blog post - noone really can or does program like that. Forget the old timers, who think that if they don't have all the power at their fingertips at all times they are not as productive as they can be - they had 50 years to write a good big program that does not crash and they failed. And lastly, forget the all the Haskell enthusiasts, if you have ever encountered this specie - they are on the hunt for the best programming architecture, which is admirable, but I prefer to have an OK architecture that is vaguely understood by, say 50 percent of all developers, than to have a perfect architecture, understood by 0.001 percent.

Pure functions
===

Of course we begin our journey with _pure_ functions. I was joking that I'd know that FP has won when I see an article about it, which does not start with "What are pure functions?". But this explanation is still needed, I think. For practical reasons you can think of a pure function in any programming language as one which:

1. In its body, it does *not* modify (mutate) the values of the arguments it accepts.
2. It also does not mutate, or change, the values of any external variables which it may have access to.
3. In its body, it only calls other pure functions.

Again, this is a _practical_ definition, and for this reason it may be quite different from the ones that you may have heard (which are often based on theory). For example you may have heard that a pure function is one which is "referentially transparent" which is a fancy way of saying that it returns the same output given the same input - this is a good definition, but it is incomplete: the `console.log` function in JS returns the same output for every input - `undefined`. That does not make it a pure function. Plus is the definition is not enough for someone who does not already know a thing or two it may leave you asking, "OK, but how do I make a function referentially transparent?". The answer to this the list above.

You may have heard that pure functions are ones that don't perform assignment. This is a nice definition, but it is a little bit sloppy. Does `console.log` perform any assigment? I can't answer that. But does `console.log` modify some external variable somewhere? Well, we can be sure that the state of our console is stored in some variable somewhere and we can also be sure that this state is changed from calling the function, so for all practical reasons it does. In fact, this is the reason we are using `console.log` in the first place - for the "side effect" - printing something on screen (as opposed to calling it for the value it produces). 


This leads us to maybe the best (and most confusing) definition of pure functions - they are the ones which have no _observable side effects_. In other words, it woudn't make any difference for our users if we call these function 10 or 100 times. It won't make any difference to them if we called the function now, or we used some cached result from calling it 10 days ago with the same arguments. The key to this definition's correctness is that it is a _subjective_ one, not an objective one. And that settles some long-standing questions, like: 

> Wait a minute, after all, all our functions write and delete some values in the registers of the CPU, so aren't all of them are really impure? And what is this "outside world" anyways? Isn't this all virtual?

Yes it is - in order to define pure functions we first define the events which are observable by our users (such as a sound coming from the speakers, the image on the screen, the time they spend waiting for a given resource to be fetched etc.) and we study the functions which don't touch those. To some people side-effect-free would mean a different thing than to others. For example you may say that logging in some file is not a side effect, simply because your users won't ever open it and you won't run out of space, so logging "doesn't count". This is OK, you will have parts of your program which will do all kinds of side effects anyways. But let's not get ahead of ourselves.

Equational Reasoning 
===

So is that distinction, the one between pure and impure functions, so important? The answer is simple: because pure functions are data. If you are interested in Lisp, you may have heard that all code is data, but for pure functions, this slogan is valid in a slightly different way: Every pure function can be represented by, and is isomorphic to, a dictionary data structure, with the function's inputs as keys, and its outputs as values. In mathematics, it is called a _function table_. I will give you an example with the function which converts an integer to a string:

```
const stringifyFn = (number) => String(number)
```

There are a finite number of integers, so it is entirely possible, and for some occasions even practical, to define such a function as a datastructire:


```
const stringifyTable = new Map([
  [1, '1'],
  [2, '2'],
  [3, '3'],
  [4, '4']
  ...
])
```
And behold: 

```
stringifyFn(1) === stringifyTable.get(1) //true
```

This will be the only example in this article, and is probably the most important example you will see if you want to understand what is FP all about. Not all functions can _really_
 be represented as data structures (many of them have infinite inputs), but all of them can be reasoned about as such. One way to grasp the power of this concept is to imagine how the function-data isomorphism scales. Imagine a simple function like the one you see above being used in a more complex but also pure function. Which is being used by a yet another one... You might define some very complex pieces of functionality, but as long as you follow the principles of purity which were stated above, what you created is an equivalent to, and can be used as, a simple datastructure, which contains keys and corresponding values. Can there be a bug in a datastructure? Well, a datastructure can be incorrect yes, but as long as it has outputs for all inputs, it will always work.

What about functions that take more than one parameter, like `(a, b) => a + b`. Well, you can think of them either as functions which take a compostite parameter(`(ab) => ab[0] + ab[1]`), or as functions who return other functions(`(a) => (b) => a + b`).

What about objects? Well, immutable objects are not excluded in any way from the party. If you have an object `x` with methods `a` and `b`, you can think of it either as a function `x` which takes one string which can be either `a` and `b` as a parameter (the name of the "message"), and one datastructure, containing the arguments. You can also think of it as an map `x`, with two functions (`a` and `b`) that just happen to share some common data. 

Using this approach, Even the most complex function constitutes nothing more, than a series of simple functions, and even the biggest taxonomy can be reduced to an ordinary datastructure from which you can just take the result, or results, that you need.

We can even identify different paths in our system which lead to the same result for the purpose of optimization, or just in order to reach better understanding of our program.

Functional Runtimes
===

If you head over to Google you can find a lot of information about how nice it is to have referential transparency and to be able to apply equational reasoning. You won't, however, have much success in finding information about what to do next. That is the topic of this chapter: how the hell creating a bunch of pure functions would help me create a GUI application, for example? Or a concurrent web server? Many functional programming tutorials seem to dismiss this question as uninteresting, but for me it is essential: running side effects is a tough job, but someone has to do it, right?

The answer to this question is "yes". But does that someone has to be me? Enter the exciting, and not very well-researched topic of functional runtimes, AKA programs that bind purely-functional programs to the real world. So what is the big idea? Simple: you design your program, you split it to two parts - one is the purely functional part which, if you are good, will be the better and bigger part of your program and the other will be the imperative part, which should be as small as possible and also as generic as possible, so many different programs can use it. Don't take the term "runtime" literally here. In some contexts, this "runtime" can be just a simple library for running purely-functional programs that solve a specific set of problems. But the runtime can also be very complex, and support many options. 

The closest thing we have to a functional runtime in the traditional programming world are the domain-specific languages, especially those of them which are not Turing-complete. Think of CSS, for example - CSS is a purely functional language that allow you to define the layout of a webpage easily and bug free. Its secret is that CSS code itself does not do anything. Most of the hard job is done by its runtime (the browser), which is not very simple, but is very versatile and can be used for a lot of things. 

CSS is, of course, not a very powerful language. Which is unfortunate: imagine having the ability to embedd some real (purely-functional) code in CSS class definition, that decides how the elements from this class be positioned, based on the position of other elements. This would allow us to be a lot more flexible when creating a dynamic layout, and still don't worry about the layout blowing in our face, bringing us many of the benefits of having access to a powerful tool, without any of the drawbacks.

Some classes of programs can be very trivially split into a purely-functional part and a runtime - think of command line tools, for example, especially those of them which only use `STDIN` and `STDOUT`, like the `grep` tool, when you forget about the `-r` option. Such tools have a very simple runtime - one which just takes the input, feeds it to the purely-functional part and when it finishes, it passes the return value to `STDOUT`.










You can view the distinction between pure and impure functions that we may make as the distinction between syncronous and asyncronous functions in platforms with non-blocking IO such as node.js. Non-blocking IO brings some very nice improvements in performance, but besides that it also brings a new mental model of the way we do programmings. At its core is the idea that functions which do network IO are special, and they should be threated differently than the ones that don't. If you think about it, in node.js, synchronous functions are those which: 

1. Do not perform any asynchronous operations.
2. Only call other synchronous functions.

So, the non-blocking paradigm resembles purely-functional programming, only it enforces purity takes care for just one type of side effect - network IO operations.




In low-level programming, _an assigment_ is the process of placing a value (like object, string etc.) in a specific memory location.

In mathematics, _a binding_ of a variable means associating it with another value, or an expression. 


The two concepts are obviously related, as the assignment was meant to work like a binding. That is why they are both denoted with the `=` sign. But there are some differences at how they typically function.

The big difference is that assignment includes places a big focus over how and when the value is computed. For example we know that the right-hand side of the expression is computed before the left one. This is what enables us to make utterly unmathematical things like `x = x + 1`, but also 
